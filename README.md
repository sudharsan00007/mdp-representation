# MDP REPRESENTATION

## AIM:

To represent a Markov Decision Process(MDP) problem.

## PROBLEM STATEMENT:
 
developing a policy to manage a car engine's heat level efficiently while optimizing the expected cumulative reward.

### Problem Description

The goal of this problem is to develop a policy that efficiently manages the engine's heat level in a car while optimizing the expected cumulative reward.

### State Space

The state space consists of two possible states:
"Cool" (representing a cool engine temperature)
"Hot" (representing a hot engine temperature)

### Sample State

A sample state might be "Cool," indicating that the engine's temperature is currently at a safe and acceptable level.

### Action Space

The action space includes two available actions:

"Accelerate" (to increase the engine's heat level)
"Brake" (to decrease the engine's heat level)

### Sample Action

A sample action could be "Brake," indicating that the driver has chosen to apply the brakes in order to reduce the engine's heat level.

### Reward Function

The rewards are structured to encourage actions that maintain the engine in the "Cool" state (reward of 1.0) and penalize actions that lead to the "Hot" state (strong penalty of -10.0).

### Graphical Representation
![265317628-c6ec3554-ea31-4e5a-b72c-fcf50fcb470e](https://github.com/user-attachments/assets/9a0a97d6-e923-4ff2-9885-de887fa4211e)


## PYTHON REPRESENTATION:


## OUTPUT:


## RESULT:

Thus, a Markov Decision Process (MDP) problem is represented in the following ways:

Text representation
Graphical representation
Python - Dictonary representation

